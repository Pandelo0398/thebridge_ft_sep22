{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.reshaping.flatten.Flatten object at 0x00000291C25211C0>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 1.2309 - accuracy: 0.7030 - val_loss: 0.5869 - val_accuracy: 0.8716\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.5086 - accuracy: 0.8712 - val_loss: 0.3909 - val_accuracy: 0.8963\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.3944 - accuracy: 0.8930 - val_loss: 0.3312 - val_accuracy: 0.9094\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3459 - accuracy: 0.9037 - val_loss: 0.2998 - val_accuracy: 0.9180\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.3161 - accuracy: 0.9120 - val_loss: 0.2784 - val_accuracy: 0.9215\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2946 - accuracy: 0.9171 - val_loss: 0.2614 - val_accuracy: 0.9268\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2772 - accuracy: 0.9224 - val_loss: 0.2479 - val_accuracy: 0.9288\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2631 - accuracy: 0.9262 - val_loss: 0.2375 - val_accuracy: 0.9326\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2507 - accuracy: 0.9299 - val_loss: 0.2286 - val_accuracy: 0.9354\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2397 - accuracy: 0.9328 - val_loss: 0.2205 - val_accuracy: 0.9369\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2300 - accuracy: 0.9350 - val_loss: 0.2139 - val_accuracy: 0.9381\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2211 - accuracy: 0.9376 - val_loss: 0.2039 - val_accuracy: 0.9430\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2127 - accuracy: 0.9404 - val_loss: 0.1979 - val_accuracy: 0.9439\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2051 - accuracy: 0.9419 - val_loss: 0.1917 - val_accuracy: 0.9464\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.1980 - accuracy: 0.9448 - val_loss: 0.1867 - val_accuracy: 0.9477\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1915 - accuracy: 0.9461 - val_loss: 0.1824 - val_accuracy: 0.9493\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1855 - accuracy: 0.9475 - val_loss: 0.1772 - val_accuracy: 0.9503\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1796 - accuracy: 0.9491 - val_loss: 0.1720 - val_accuracy: 0.9518\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1741 - accuracy: 0.9506 - val_loss: 0.1683 - val_accuracy: 0.9538\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1688 - accuracy: 0.9517 - val_loss: 0.1643 - val_accuracy: 0.9543\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1638 - accuracy: 0.9537 - val_loss: 0.1611 - val_accuracy: 0.9560\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1594 - accuracy: 0.9546 - val_loss: 0.1573 - val_accuracy: 0.9569\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1550 - accuracy: 0.9557 - val_loss: 0.1524 - val_accuracy: 0.9584\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1505 - accuracy: 0.9571 - val_loss: 0.1506 - val_accuracy: 0.9583\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1466 - accuracy: 0.9585 - val_loss: 0.1469 - val_accuracy: 0.9594\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1427 - accuracy: 0.9594 - val_loss: 0.1439 - val_accuracy: 0.9610\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1387 - accuracy: 0.9608 - val_loss: 0.1432 - val_accuracy: 0.9616\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.1352 - accuracy: 0.9619 - val_loss: 0.1392 - val_accuracy: 0.9631\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1319 - accuracy: 0.9628 - val_loss: 0.1358 - val_accuracy: 0.9640\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1286 - accuracy: 0.9635 - val_loss: 0.1336 - val_accuracy: 0.9646\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1253 - accuracy: 0.9646 - val_loss: 0.1314 - val_accuracy: 0.9654\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1223 - accuracy: 0.9659 - val_loss: 0.1295 - val_accuracy: 0.9654\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1196 - accuracy: 0.9663 - val_loss: 0.1271 - val_accuracy: 0.9663\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.1167 - accuracy: 0.9675 - val_loss: 0.1261 - val_accuracy: 0.9672\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1140 - accuracy: 0.9685 - val_loss: 0.1251 - val_accuracy: 0.9675\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1113 - accuracy: 0.9689 - val_loss: 0.1219 - val_accuracy: 0.9671\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1090 - accuracy: 0.9695 - val_loss: 0.1201 - val_accuracy: 0.9682\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1064 - accuracy: 0.9704 - val_loss: 0.1187 - val_accuracy: 0.9681\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1041 - accuracy: 0.9710 - val_loss: 0.1171 - val_accuracy: 0.9692\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1019 - accuracy: 0.9719 - val_loss: 0.1165 - val_accuracy: 0.9699\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0997 - accuracy: 0.9730 - val_loss: 0.1142 - val_accuracy: 0.9694\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0976 - accuracy: 0.9730 - val_loss: 0.1121 - val_accuracy: 0.9703\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0954 - accuracy: 0.9734 - val_loss: 0.1124 - val_accuracy: 0.9691\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0936 - accuracy: 0.9745 - val_loss: 0.1099 - val_accuracy: 0.9708\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 0.0916 - accuracy: 0.9746 - val_loss: 0.1092 - val_accuracy: 0.9710\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0897 - accuracy: 0.9757 - val_loss: 0.1085 - val_accuracy: 0.9706\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0879 - accuracy: 0.9762 - val_loss: 0.1073 - val_accuracy: 0.9708\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0862 - accuracy: 0.9767 - val_loss: 0.1048 - val_accuracy: 0.9716\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0846 - accuracy: 0.9769 - val_loss: 0.1043 - val_accuracy: 0.9720\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 0.0828 - accuracy: 0.9777 - val_loss: 0.1034 - val_accuracy: 0.9718\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0823 - accuracy: 0.9776 - val_loss: 0.1036 - val_accuracy: 0.9715\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0793 - accuracy: 0.9788 - val_loss: 0.1024 - val_accuracy: 0.9705\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0764 - accuracy: 0.9793 - val_loss: 0.0990 - val_accuracy: 0.9726\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0734 - accuracy: 0.9806 - val_loss: 0.0981 - val_accuracy: 0.9728\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0710 - accuracy: 0.9813 - val_loss: 0.0952 - val_accuracy: 0.9732\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0684 - accuracy: 0.9817 - val_loss: 0.0957 - val_accuracy: 0.9734\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0662 - accuracy: 0.9820 - val_loss: 0.0932 - val_accuracy: 0.9741\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0640 - accuracy: 0.9829 - val_loss: 0.0922 - val_accuracy: 0.9741\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0616 - accuracy: 0.9837 - val_loss: 0.0911 - val_accuracy: 0.9739\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0595 - accuracy: 0.9845 - val_loss: 0.0910 - val_accuracy: 0.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291c1e27eb0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 50, 'steps': 391}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2309186458587646,\n",
       "  0.5086420178413391,\n",
       "  0.39438381791114807,\n",
       "  0.34586670994758606,\n",
       "  0.3160732090473175,\n",
       "  0.2946191728115082,\n",
       "  0.27719610929489136,\n",
       "  0.2631065845489502,\n",
       "  0.25069624185562134,\n",
       "  0.23971286416053772,\n",
       "  0.22996097803115845,\n",
       "  0.22110728919506073,\n",
       "  0.21270334720611572,\n",
       "  0.20508326590061188,\n",
       "  0.19803979992866516,\n",
       "  0.191539466381073,\n",
       "  0.1854649931192398,\n",
       "  0.17955482006072998,\n",
       "  0.1740543395280838,\n",
       "  0.16879330575466156,\n",
       "  0.1638047695159912,\n",
       "  0.15943367779254913,\n",
       "  0.15495753288269043,\n",
       "  0.15048745274543762,\n",
       "  0.1465872824192047,\n",
       "  0.14273959398269653,\n",
       "  0.13872170448303223,\n",
       "  0.13515128195285797,\n",
       "  0.1318802386522293,\n",
       "  0.1286495476961136,\n",
       "  0.1252889335155487,\n",
       "  0.12232252210378647,\n",
       "  0.11962677538394928,\n",
       "  0.11671791225671768,\n",
       "  0.11395543068647385,\n",
       "  0.11134311556816101,\n",
       "  0.10897057503461838,\n",
       "  0.10639074444770813,\n",
       "  0.1041431799530983,\n",
       "  0.10191762447357178,\n",
       "  0.09971790760755539,\n",
       "  0.09755285829305649,\n",
       "  0.09540268778800964,\n",
       "  0.09360295534133911,\n",
       "  0.09162210673093796,\n",
       "  0.08972293883562088,\n",
       "  0.08788269758224487,\n",
       "  0.0862397775053978,\n",
       "  0.08456678688526154,\n",
       "  0.08283071219921112],\n",
       " 'accuracy': [0.7030400037765503,\n",
       "  0.8712400197982788,\n",
       "  0.8929799795150757,\n",
       "  0.9037200212478638,\n",
       "  0.9119600057601929,\n",
       "  0.917140007019043,\n",
       "  0.9224399924278259,\n",
       "  0.9262199997901917,\n",
       "  0.9298999905586243,\n",
       "  0.9327800273895264,\n",
       "  0.9349600076675415,\n",
       "  0.9376400113105774,\n",
       "  0.9403600096702576,\n",
       "  0.9419400095939636,\n",
       "  0.9448000192642212,\n",
       "  0.9460999965667725,\n",
       "  0.9474599957466125,\n",
       "  0.9491400122642517,\n",
       "  0.9505599737167358,\n",
       "  0.9516800045967102,\n",
       "  0.9537000060081482,\n",
       "  0.9545800089836121,\n",
       "  0.9556999802589417,\n",
       "  0.9571400284767151,\n",
       "  0.9584599733352661,\n",
       "  0.9594399929046631,\n",
       "  0.9607800245285034,\n",
       "  0.9619399905204773,\n",
       "  0.9628199934959412,\n",
       "  0.9635000228881836,\n",
       "  0.9646199941635132,\n",
       "  0.9658799767494202,\n",
       "  0.9662799835205078,\n",
       "  0.9674800038337708,\n",
       "  0.9684799909591675,\n",
       "  0.968940019607544,\n",
       "  0.9695000052452087,\n",
       "  0.9704399704933167,\n",
       "  0.9710400104522705,\n",
       "  0.9718599915504456,\n",
       "  0.9729999899864197,\n",
       "  0.9729999899864197,\n",
       "  0.9734200239181519,\n",
       "  0.9744799733161926,\n",
       "  0.9746000170707703,\n",
       "  0.9757199883460999,\n",
       "  0.9762200117111206,\n",
       "  0.9766799807548523,\n",
       "  0.9768999814987183,\n",
       "  0.9777200222015381],\n",
       " 'val_loss': [0.5868660807609558,\n",
       "  0.3908540904521942,\n",
       "  0.3311823606491089,\n",
       "  0.2997855544090271,\n",
       "  0.2784169912338257,\n",
       "  0.26136019825935364,\n",
       "  0.24789948761463165,\n",
       "  0.23749031126499176,\n",
       "  0.22856327891349792,\n",
       "  0.22054342925548553,\n",
       "  0.21389181911945343,\n",
       "  0.20391468703746796,\n",
       "  0.19786633551120758,\n",
       "  0.19167014956474304,\n",
       "  0.1866695135831833,\n",
       "  0.18243154883384705,\n",
       "  0.17724590003490448,\n",
       "  0.17203398048877716,\n",
       "  0.16829264163970947,\n",
       "  0.1643420159816742,\n",
       "  0.16114337742328644,\n",
       "  0.1572732925415039,\n",
       "  0.15242810547351837,\n",
       "  0.1505863219499588,\n",
       "  0.14693723618984222,\n",
       "  0.1439131647348404,\n",
       "  0.1431557834148407,\n",
       "  0.13920463621616364,\n",
       "  0.13577017188072205,\n",
       "  0.13361385464668274,\n",
       "  0.13144788146018982,\n",
       "  0.12950652837753296,\n",
       "  0.1270991861820221,\n",
       "  0.12608444690704346,\n",
       "  0.12509344518184662,\n",
       "  0.12194634974002838,\n",
       "  0.12013436108827591,\n",
       "  0.11866988241672516,\n",
       "  0.11714328825473785,\n",
       "  0.11652062088251114,\n",
       "  0.11420381814241409,\n",
       "  0.1121409460902214,\n",
       "  0.11238157004117966,\n",
       "  0.10994687676429749,\n",
       "  0.10919388383626938,\n",
       "  0.10848991572856903,\n",
       "  0.10727643966674805,\n",
       "  0.10480323433876038,\n",
       "  0.10431861877441406,\n",
       "  0.10339798778295517],\n",
       " 'val_accuracy': [0.8715999722480774,\n",
       "  0.8963000178337097,\n",
       "  0.9093999862670898,\n",
       "  0.9179999828338623,\n",
       "  0.921500027179718,\n",
       "  0.926800012588501,\n",
       "  0.9287999868392944,\n",
       "  0.9326000213623047,\n",
       "  0.9354000091552734,\n",
       "  0.9369000196456909,\n",
       "  0.9380999803543091,\n",
       "  0.9430000185966492,\n",
       "  0.9438999891281128,\n",
       "  0.946399986743927,\n",
       "  0.947700023651123,\n",
       "  0.9492999911308289,\n",
       "  0.9502999782562256,\n",
       "  0.9517999887466431,\n",
       "  0.9538000226020813,\n",
       "  0.9542999863624573,\n",
       "  0.9559999704360962,\n",
       "  0.9569000005722046,\n",
       "  0.9584000110626221,\n",
       "  0.958299994468689,\n",
       "  0.9593999981880188,\n",
       "  0.9610000252723694,\n",
       "  0.9616000056266785,\n",
       "  0.963100016117096,\n",
       "  0.9639999866485596,\n",
       "  0.9646000266075134,\n",
       "  0.965399980545044,\n",
       "  0.965399980545044,\n",
       "  0.9663000106811523,\n",
       "  0.967199981212616,\n",
       "  0.9674999713897705,\n",
       "  0.9671000242233276,\n",
       "  0.9682000279426575,\n",
       "  0.9681000113487244,\n",
       "  0.9692000150680542,\n",
       "  0.9699000120162964,\n",
       "  0.9693999886512756,\n",
       "  0.970300018787384,\n",
       "  0.9690999984741211,\n",
       "  0.97079998254776,\n",
       "  0.9710000157356262,\n",
       "  0.9706000089645386,\n",
       "  0.97079998254776,\n",
       "  0.9715999960899353,\n",
       "  0.972000002861023,\n",
       "  0.9718000292778015]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2309186458587646,\n",
       "  0.5086420178413391,\n",
       "  0.39438381791114807,\n",
       "  0.34586670994758606,\n",
       "  0.3160732090473175,\n",
       "  0.2946191728115082,\n",
       "  0.27719610929489136,\n",
       "  0.2631065845489502,\n",
       "  0.25069624185562134,\n",
       "  0.23971286416053772,\n",
       "  0.22996097803115845,\n",
       "  0.22110728919506073,\n",
       "  0.21270334720611572,\n",
       "  0.20508326590061188,\n",
       "  0.19803979992866516,\n",
       "  0.191539466381073,\n",
       "  0.1854649931192398,\n",
       "  0.17955482006072998,\n",
       "  0.1740543395280838,\n",
       "  0.16879330575466156,\n",
       "  0.1638047695159912,\n",
       "  0.15943367779254913,\n",
       "  0.15495753288269043,\n",
       "  0.15048745274543762,\n",
       "  0.1465872824192047,\n",
       "  0.14273959398269653,\n",
       "  0.13872170448303223,\n",
       "  0.13515128195285797,\n",
       "  0.1318802386522293,\n",
       "  0.1286495476961136,\n",
       "  0.1252889335155487,\n",
       "  0.12232252210378647,\n",
       "  0.11962677538394928,\n",
       "  0.11671791225671768,\n",
       "  0.11395543068647385,\n",
       "  0.11134311556816101,\n",
       "  0.10897057503461838,\n",
       "  0.10639074444770813,\n",
       "  0.1041431799530983,\n",
       "  0.10191762447357178,\n",
       "  0.09971790760755539,\n",
       "  0.09755285829305649,\n",
       "  0.09540268778800964,\n",
       "  0.09360295534133911,\n",
       "  0.09162210673093796,\n",
       "  0.08972293883562088,\n",
       "  0.08788269758224487,\n",
       "  0.0862397775053978,\n",
       "  0.08456678688526154,\n",
       "  0.08283071219921112],\n",
       " 'accuracy': [0.7030400037765503,\n",
       "  0.8712400197982788,\n",
       "  0.8929799795150757,\n",
       "  0.9037200212478638,\n",
       "  0.9119600057601929,\n",
       "  0.917140007019043,\n",
       "  0.9224399924278259,\n",
       "  0.9262199997901917,\n",
       "  0.9298999905586243,\n",
       "  0.9327800273895264,\n",
       "  0.9349600076675415,\n",
       "  0.9376400113105774,\n",
       "  0.9403600096702576,\n",
       "  0.9419400095939636,\n",
       "  0.9448000192642212,\n",
       "  0.9460999965667725,\n",
       "  0.9474599957466125,\n",
       "  0.9491400122642517,\n",
       "  0.9505599737167358,\n",
       "  0.9516800045967102,\n",
       "  0.9537000060081482,\n",
       "  0.9545800089836121,\n",
       "  0.9556999802589417,\n",
       "  0.9571400284767151,\n",
       "  0.9584599733352661,\n",
       "  0.9594399929046631,\n",
       "  0.9607800245285034,\n",
       "  0.9619399905204773,\n",
       "  0.9628199934959412,\n",
       "  0.9635000228881836,\n",
       "  0.9646199941635132,\n",
       "  0.9658799767494202,\n",
       "  0.9662799835205078,\n",
       "  0.9674800038337708,\n",
       "  0.9684799909591675,\n",
       "  0.968940019607544,\n",
       "  0.9695000052452087,\n",
       "  0.9704399704933167,\n",
       "  0.9710400104522705,\n",
       "  0.9718599915504456,\n",
       "  0.9729999899864197,\n",
       "  0.9729999899864197,\n",
       "  0.9734200239181519,\n",
       "  0.9744799733161926,\n",
       "  0.9746000170707703,\n",
       "  0.9757199883460999,\n",
       "  0.9762200117111206,\n",
       "  0.9766799807548523,\n",
       "  0.9768999814987183,\n",
       "  0.9777200222015381],\n",
       " 'val_loss': [0.5868660807609558,\n",
       "  0.3908540904521942,\n",
       "  0.3311823606491089,\n",
       "  0.2997855544090271,\n",
       "  0.2784169912338257,\n",
       "  0.26136019825935364,\n",
       "  0.24789948761463165,\n",
       "  0.23749031126499176,\n",
       "  0.22856327891349792,\n",
       "  0.22054342925548553,\n",
       "  0.21389181911945343,\n",
       "  0.20391468703746796,\n",
       "  0.19786633551120758,\n",
       "  0.19167014956474304,\n",
       "  0.1866695135831833,\n",
       "  0.18243154883384705,\n",
       "  0.17724590003490448,\n",
       "  0.17203398048877716,\n",
       "  0.16829264163970947,\n",
       "  0.1643420159816742,\n",
       "  0.16114337742328644,\n",
       "  0.1572732925415039,\n",
       "  0.15242810547351837,\n",
       "  0.1505863219499588,\n",
       "  0.14693723618984222,\n",
       "  0.1439131647348404,\n",
       "  0.1431557834148407,\n",
       "  0.13920463621616364,\n",
       "  0.13577017188072205,\n",
       "  0.13361385464668274,\n",
       "  0.13144788146018982,\n",
       "  0.12950652837753296,\n",
       "  0.1270991861820221,\n",
       "  0.12608444690704346,\n",
       "  0.12509344518184662,\n",
       "  0.12194634974002838,\n",
       "  0.12013436108827591,\n",
       "  0.11866988241672516,\n",
       "  0.11714328825473785,\n",
       "  0.11652062088251114,\n",
       "  0.11420381814241409,\n",
       "  0.1121409460902214,\n",
       "  0.11238157004117966,\n",
       "  0.10994687676429749,\n",
       "  0.10919388383626938,\n",
       "  0.10848991572856903,\n",
       "  0.10727643966674805,\n",
       "  0.10480323433876038,\n",
       "  0.10431861877441406,\n",
       "  0.10339798778295517],\n",
       " 'val_accuracy': [0.8715999722480774,\n",
       "  0.8963000178337097,\n",
       "  0.9093999862670898,\n",
       "  0.9179999828338623,\n",
       "  0.921500027179718,\n",
       "  0.926800012588501,\n",
       "  0.9287999868392944,\n",
       "  0.9326000213623047,\n",
       "  0.9354000091552734,\n",
       "  0.9369000196456909,\n",
       "  0.9380999803543091,\n",
       "  0.9430000185966492,\n",
       "  0.9438999891281128,\n",
       "  0.946399986743927,\n",
       "  0.947700023651123,\n",
       "  0.9492999911308289,\n",
       "  0.9502999782562256,\n",
       "  0.9517999887466431,\n",
       "  0.9538000226020813,\n",
       "  0.9542999863624573,\n",
       "  0.9559999704360962,\n",
       "  0.9569000005722046,\n",
       "  0.9584000110626221,\n",
       "  0.958299994468689,\n",
       "  0.9593999981880188,\n",
       "  0.9610000252723694,\n",
       "  0.9616000056266785,\n",
       "  0.963100016117096,\n",
       "  0.9639999866485596,\n",
       "  0.9646000266075134,\n",
       "  0.965399980545044,\n",
       "  0.965399980545044,\n",
       "  0.9663000106811523,\n",
       "  0.967199981212616,\n",
       "  0.9674999713897705,\n",
       "  0.9671000242233276,\n",
       "  0.9682000279426575,\n",
       "  0.9681000113487244,\n",
       "  0.9692000150680542,\n",
       "  0.9699000120162964,\n",
       "  0.9693999886512756,\n",
       "  0.970300018787384,\n",
       "  0.9690999984741211,\n",
       "  0.97079998254776,\n",
       "  0.9710000157356262,\n",
       "  0.9706000089645386,\n",
       "  0.97079998254776,\n",
       "  0.9715999960899353,\n",
       "  0.972000002861023,\n",
       "  0.9718000292778015]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.230919</td>\n",
       "      <td>0.70304</td>\n",
       "      <td>0.586866</td>\n",
       "      <td>0.8716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.508642</td>\n",
       "      <td>0.87124</td>\n",
       "      <td>0.390854</td>\n",
       "      <td>0.8963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.394384</td>\n",
       "      <td>0.89298</td>\n",
       "      <td>0.331182</td>\n",
       "      <td>0.9094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.345867</td>\n",
       "      <td>0.90372</td>\n",
       "      <td>0.299786</td>\n",
       "      <td>0.9180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.316073</td>\n",
       "      <td>0.91196</td>\n",
       "      <td>0.278417</td>\n",
       "      <td>0.9215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294619</td>\n",
       "      <td>0.91714</td>\n",
       "      <td>0.261360</td>\n",
       "      <td>0.9268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.277196</td>\n",
       "      <td>0.92244</td>\n",
       "      <td>0.247899</td>\n",
       "      <td>0.9288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.263107</td>\n",
       "      <td>0.92622</td>\n",
       "      <td>0.237490</td>\n",
       "      <td>0.9326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.250696</td>\n",
       "      <td>0.92990</td>\n",
       "      <td>0.228563</td>\n",
       "      <td>0.9354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.239713</td>\n",
       "      <td>0.93278</td>\n",
       "      <td>0.220543</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.229961</td>\n",
       "      <td>0.93496</td>\n",
       "      <td>0.213892</td>\n",
       "      <td>0.9381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.221107</td>\n",
       "      <td>0.93764</td>\n",
       "      <td>0.203915</td>\n",
       "      <td>0.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.212703</td>\n",
       "      <td>0.94036</td>\n",
       "      <td>0.197866</td>\n",
       "      <td>0.9439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.205083</td>\n",
       "      <td>0.94194</td>\n",
       "      <td>0.191670</td>\n",
       "      <td>0.9464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.198040</td>\n",
       "      <td>0.94480</td>\n",
       "      <td>0.186670</td>\n",
       "      <td>0.9477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.191539</td>\n",
       "      <td>0.94610</td>\n",
       "      <td>0.182432</td>\n",
       "      <td>0.9493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.185465</td>\n",
       "      <td>0.94746</td>\n",
       "      <td>0.177246</td>\n",
       "      <td>0.9503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.179555</td>\n",
       "      <td>0.94914</td>\n",
       "      <td>0.172034</td>\n",
       "      <td>0.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.174054</td>\n",
       "      <td>0.95056</td>\n",
       "      <td>0.168293</td>\n",
       "      <td>0.9538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.168793</td>\n",
       "      <td>0.95168</td>\n",
       "      <td>0.164342</td>\n",
       "      <td>0.9543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.163805</td>\n",
       "      <td>0.95370</td>\n",
       "      <td>0.161143</td>\n",
       "      <td>0.9560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.159434</td>\n",
       "      <td>0.95458</td>\n",
       "      <td>0.157273</td>\n",
       "      <td>0.9569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.154958</td>\n",
       "      <td>0.95570</td>\n",
       "      <td>0.152428</td>\n",
       "      <td>0.9584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.150487</td>\n",
       "      <td>0.95714</td>\n",
       "      <td>0.150586</td>\n",
       "      <td>0.9583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.146587</td>\n",
       "      <td>0.95846</td>\n",
       "      <td>0.146937</td>\n",
       "      <td>0.9594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.142740</td>\n",
       "      <td>0.95944</td>\n",
       "      <td>0.143913</td>\n",
       "      <td>0.9610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.138722</td>\n",
       "      <td>0.96078</td>\n",
       "      <td>0.143156</td>\n",
       "      <td>0.9616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.135151</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.139205</td>\n",
       "      <td>0.9631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.131880</td>\n",
       "      <td>0.96282</td>\n",
       "      <td>0.135770</td>\n",
       "      <td>0.9640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.128650</td>\n",
       "      <td>0.96350</td>\n",
       "      <td>0.133614</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.125289</td>\n",
       "      <td>0.96462</td>\n",
       "      <td>0.131448</td>\n",
       "      <td>0.9654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.122323</td>\n",
       "      <td>0.96588</td>\n",
       "      <td>0.129507</td>\n",
       "      <td>0.9654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.119627</td>\n",
       "      <td>0.96628</td>\n",
       "      <td>0.127099</td>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.116718</td>\n",
       "      <td>0.96748</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.9672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.113955</td>\n",
       "      <td>0.96848</td>\n",
       "      <td>0.125093</td>\n",
       "      <td>0.9675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.111343</td>\n",
       "      <td>0.96894</td>\n",
       "      <td>0.121946</td>\n",
       "      <td>0.9671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.108971</td>\n",
       "      <td>0.96950</td>\n",
       "      <td>0.120134</td>\n",
       "      <td>0.9682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.106391</td>\n",
       "      <td>0.97044</td>\n",
       "      <td>0.118670</td>\n",
       "      <td>0.9681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.104143</td>\n",
       "      <td>0.97104</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>0.9692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.101918</td>\n",
       "      <td>0.97186</td>\n",
       "      <td>0.116521</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.099718</td>\n",
       "      <td>0.97300</td>\n",
       "      <td>0.114204</td>\n",
       "      <td>0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.097553</td>\n",
       "      <td>0.97300</td>\n",
       "      <td>0.112141</td>\n",
       "      <td>0.9703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.095403</td>\n",
       "      <td>0.97342</td>\n",
       "      <td>0.112382</td>\n",
       "      <td>0.9691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.093603</td>\n",
       "      <td>0.97448</td>\n",
       "      <td>0.109947</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.091622</td>\n",
       "      <td>0.97460</td>\n",
       "      <td>0.109194</td>\n",
       "      <td>0.9710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.089723</td>\n",
       "      <td>0.97572</td>\n",
       "      <td>0.108490</td>\n",
       "      <td>0.9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.087883</td>\n",
       "      <td>0.97622</td>\n",
       "      <td>0.107276</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.086240</td>\n",
       "      <td>0.97668</td>\n",
       "      <td>0.104803</td>\n",
       "      <td>0.9716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.084567</td>\n",
       "      <td>0.97690</td>\n",
       "      <td>0.104319</td>\n",
       "      <td>0.9720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.082831</td>\n",
       "      <td>0.97772</td>\n",
       "      <td>0.103398</td>\n",
       "      <td>0.9718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.230919   0.70304  0.586866        0.8716\n",
       "1   0.508642   0.87124  0.390854        0.8963\n",
       "2   0.394384   0.89298  0.331182        0.9094\n",
       "3   0.345867   0.90372  0.299786        0.9180\n",
       "4   0.316073   0.91196  0.278417        0.9215\n",
       "5   0.294619   0.91714  0.261360        0.9268\n",
       "6   0.277196   0.92244  0.247899        0.9288\n",
       "7   0.263107   0.92622  0.237490        0.9326\n",
       "8   0.250696   0.92990  0.228563        0.9354\n",
       "9   0.239713   0.93278  0.220543        0.9369\n",
       "10  0.229961   0.93496  0.213892        0.9381\n",
       "11  0.221107   0.93764  0.203915        0.9430\n",
       "12  0.212703   0.94036  0.197866        0.9439\n",
       "13  0.205083   0.94194  0.191670        0.9464\n",
       "14  0.198040   0.94480  0.186670        0.9477\n",
       "15  0.191539   0.94610  0.182432        0.9493\n",
       "16  0.185465   0.94746  0.177246        0.9503\n",
       "17  0.179555   0.94914  0.172034        0.9518\n",
       "18  0.174054   0.95056  0.168293        0.9538\n",
       "19  0.168793   0.95168  0.164342        0.9543\n",
       "20  0.163805   0.95370  0.161143        0.9560\n",
       "21  0.159434   0.95458  0.157273        0.9569\n",
       "22  0.154958   0.95570  0.152428        0.9584\n",
       "23  0.150487   0.95714  0.150586        0.9583\n",
       "24  0.146587   0.95846  0.146937        0.9594\n",
       "25  0.142740   0.95944  0.143913        0.9610\n",
       "26  0.138722   0.96078  0.143156        0.9616\n",
       "27  0.135151   0.96194  0.139205        0.9631\n",
       "28  0.131880   0.96282  0.135770        0.9640\n",
       "29  0.128650   0.96350  0.133614        0.9646\n",
       "30  0.125289   0.96462  0.131448        0.9654\n",
       "31  0.122323   0.96588  0.129507        0.9654\n",
       "32  0.119627   0.96628  0.127099        0.9663\n",
       "33  0.116718   0.96748  0.126084        0.9672\n",
       "34  0.113955   0.96848  0.125093        0.9675\n",
       "35  0.111343   0.96894  0.121946        0.9671\n",
       "36  0.108971   0.96950  0.120134        0.9682\n",
       "37  0.106391   0.97044  0.118670        0.9681\n",
       "38  0.104143   0.97104  0.117143        0.9692\n",
       "39  0.101918   0.97186  0.116521        0.9699\n",
       "40  0.099718   0.97300  0.114204        0.9694\n",
       "41  0.097553   0.97300  0.112141        0.9703\n",
       "42  0.095403   0.97342  0.112382        0.9691\n",
       "43  0.093603   0.97448  0.109947        0.9708\n",
       "44  0.091622   0.97460  0.109194        0.9710\n",
       "45  0.089723   0.97572  0.108490        0.9706\n",
       "46  0.087883   0.97622  0.107276        0.9708\n",
       "47  0.086240   0.97668  0.104803        0.9716\n",
       "48  0.084567   0.97690  0.104319        0.9720\n",
       "49  0.082831   0.97772  0.103398        0.9718"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09028011560440063, 0.9739000201225281]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 1.2588 - val_loss: 0.5362\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4812 - val_loss: 0.3943\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3797 - val_loss: 0.3840\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3717 - val_loss: 0.3829\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3667 - val_loss: 0.3742\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3635 - val_loss: 0.3782\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.3729\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3571 - val_loss: 0.3674\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3559 - val_loss: 0.3692\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3542 - val_loss: 0.3624\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.3642\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3536 - val_loss: 0.3575\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.3653\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3471 - val_loss: 0.3593\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3593\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3433 - val_loss: 0.3527\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3418 - val_loss: 0.3503\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3388 - val_loss: 0.3596\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3380 - val_loss: 0.3628\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3357 - val_loss: 0.3549\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 30)                270       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3666\n",
      "0.3666249215602875\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.73318636],\n",
       "       [3.9016314 ],\n",
       "       [1.555244  ],\n",
       "       [1.5166186 ],\n",
       "       [2.2759764 ]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3384\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3333\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3316\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3303\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3284\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3292\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3249\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3252\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3237\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3244\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3207\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3246\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3232\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3185\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3193\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3177\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3181\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3176\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3150\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3158\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3170\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3140\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3134\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3192\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3126\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3121\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3111\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3145\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3149\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3110\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3136 - val_loss: 0.3285\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3126 - val_loss: 0.3276\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.3295\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3089 - val_loss: 0.3309\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3100 - val_loss: 0.3285\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3085 - val_loss: 0.3291\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3071 - val_loss: 0.3369\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=20,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
